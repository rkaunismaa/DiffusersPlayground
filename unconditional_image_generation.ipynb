{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Wednesday, Jaunary 3, 2024\n",
        "\n",
        "[Unconditional Image Generation](https://huggingface.co/docs/diffusers/using-diffusers/unconditional_image_generation)\n",
        "\n",
        "docker container start hfpt_Dec14\n",
        "\n",
        "This all runs ... but is kinda lame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyeAGQt1Y4Gw"
      },
      "source": [
        "# Unconditional image generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GAByiAWY4Gy"
      },
      "source": [
        "Unconditional image generation is a relatively straightforward task. The model only generates images - without any additional context like text or an image - resembling the training data it was trained on.\n",
        "\n",
        "The [DiffusionPipeline](https://huggingface.co/docs/diffusers/main/en/api/pipelines/overview#diffusers.DiffusionPipeline) is the easiest way to use a pre-trained diffusion system for inference.\n",
        "\n",
        "Start by creating an instance of [DiffusionPipeline](https://huggingface.co/docs/diffusers/main/en/api/pipelines/overview#diffusers.DiffusionPipeline) and specify which pipeline checkpoint you would like to download.\n",
        "You can use any of the ðŸ§¨ Diffusers [checkpoints](https://huggingface.co/models?library=diffusers&sort=downloads) from the Hub (the checkpoint you'll use generates images of butterflies).\n",
        "\n",
        "<Tip>\n",
        "\n",
        "ðŸ’¡ Want to train your own unconditional image generation model? Take a look at the training [guide](https://huggingface.co/docs/diffusers/main/en/using-diffusers/training/unconditional_training) to learn how to generate your own images.\n",
        "\n",
        "</Tip>\n",
        "\n",
        "In this guide, you'll use [DiffusionPipeline](https://huggingface.co/docs/diffusers/main/en/api/pipelines/overview#diffusers.DiffusionPipeline) for unconditional image generation with [DDPM](https://arxiv.org/abs/2006.11239):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jGlX7_jnY4Gz"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e40ab5a868c849aa9fb69ad2bac93077",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model_index.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a40c97e863ae4545b40a0b63b322ca1d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ce948da08cf4315a50a9dfb39910d97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "unet/config.json:   0%|          | 0.00/852 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4fd68a6499f24999bcc77f45e6d69b9f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "scheduler/scheduler_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fdd0237e47184b31ba2aa0e6be954558",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "diffusion_pytorch_model.safetensors:   0%|          | 0.00/455M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2167ed23cb9a4e03b75aea0f30fa1480",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "generator = DiffusionPipeline.from_pretrained(\"anton-l/ddpm-butterflies-128\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJwy3rvUY4G0"
      },
      "source": [
        "The [DiffusionPipeline](https://huggingface.co/docs/diffusers/main/en/api/pipelines/overview#diffusers.DiffusionPipeline) downloads and caches all modeling, tokenization, and scheduling components.\n",
        "Because the model consists of roughly 1.4 billion parameters, we strongly recommend running it on a GPU.\n",
        "You can move the generator object to a GPU, just like you would in PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "models--CompVis--stable-diffusion-v1-4\n",
            "models--TheBloke--CodeLlama-34B-Instruct-GPTQ\n",
            "models--TheBloke--Llama-2-13b-Chat-GPTQ\n",
            "models--anton-l--ddpm-butterflies-128\n",
            "models--google--ddpm-cat-256\n",
            "models--google--ddpm-celebahq-256\n",
            "models--google--ddpm-church-256\n",
            "models--microsoft--Orca-2-13b\n",
            "models--mistralai--Mistral-7B-Instruct-v0.2\n",
            "models--nitrosocke--Ghibli-Diffusion\n",
            "models--runwayml--stable-diffusion-v1-5\n",
            "models--stabilityai--sd-vae-ft-mse\n",
            "version.txt\n",
            "version_diffusers_cache.txt\n"
          ]
        }
      ],
      "source": [
        "!ls /root/.cache/huggingface/hub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# docker cp c8324b70601d:///root/.cache/huggingface/hub/models--anton-l--ddpm-butterflies-128 /home/rob/Data3/huggingface/transformers\n",
        "# Successfully copied 455MB to /home/rob/Data3/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "k2ieZQBVY4G0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DDPMPipeline {\n",
              "  \"_class_name\": \"DDPMPipeline\",\n",
              "  \"_diffusers_version\": \"0.25.0\",\n",
              "  \"_name_or_path\": \"anton-l/ddpm-butterflies-128\",\n",
              "  \"scheduler\": [\n",
              "    \"diffusers\",\n",
              "    \"DDPMScheduler\"\n",
              "  ],\n",
              "  \"unet\": [\n",
              "    \"diffusers\",\n",
              "    \"UNet2DModel\"\n",
              "  ]\n",
              "}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generator.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeyZqJ8cY4G1"
      },
      "source": [
        "Now you can use the `generator` to generate an image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5i0igYL_Y4G1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa4e7a522bd8476db7dd897b17b026df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "image = generator().images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9waGyj6OY4G1"
      },
      "source": [
        "The output is by default wrapped into a [`PIL.Image`](https://pillow.readthedocs.io/en/stable/reference/Image.html?highlight=image#the-image-class) object.\n",
        "\n",
        "You can save the image by calling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "a_1ex50EY4G1"
      },
      "outputs": [],
      "source": [
        "image.save(\"generated_image.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b50nArV1Y4G2"
      },
      "source": [
        "Try out the Spaces below, and feel free to play around with the inference steps parameter to see how it affects the image quality!\n",
        "\n",
        "<iframe\n",
        "\tsrc=\"https://stevhliu-ddpm-butterflies-128.hf.space\"\n",
        "\tframeborder=\"0\"\n",
        "\twidth=\"850\"\n",
        "\theight=\"500\"\n",
        "></iframe>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
